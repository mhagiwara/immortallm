良い研究をするためには—学生・研究者のための実践ガイド

・良い研究とは？
・研究トピックの選び方
・研究を進めるコツ

様々な環境で研究してきた自分の経験と、
指導してきた同僚・インターン、学生さんによくアドバイスする点です。
特に、AI / ML の分野で研究する方向きです。

Section 1
--------------------------------------------------------------------------------
これまで20年にわたる自分の研究経験

自分も良い研究をしてきたとは言えない

大企業 (Microsoft)
スタートアップ (Duolingo)
アカデミア (博士課程、現在所属している Earth Species Project 非営利団体)
フリーランス

言語処理学会で最優秀論文賞
COLING、言語学・NLP の学会でベストペーパー候補
ICLR でコアの著者の一人として論文採択

幅広い環境、トピックで研究経験
共同研究者、後輩、インターン
アドバイスした内容がベース


本エピソードの対象者

修士・博士課程・ポスドク
アカデミア・企業の研究者

割と研究トピックの選択に自由が効く人向け

×
企業の開発者・エンジニア
スタートアップ


-------------------------------------------------------------------------------
なぜ良い研究をするか

論文を出したい、国内学会・国際学会で発表したい、自分のキャリアに繋げたい
コミュニティに貢献したい

研究の量より質が重要

MIT の Bill Freeman氏「How to write a good research paper」
横軸　研究のクオリティ
縦軸　自分のキャリアへの影響

グラフを見ると、「悪い論文」から「まあまあ良い論文」までは、キャリアへの影響はほとんどありません。ほぼゼロに近いです。

しかし、「クリエイティブで、オリジナリティがあり、かつ質の高い論文」になると、急激にキャリアへの影響が大きくなります。グラフの赤い線が急に跳ね上がっているのがその証拠です。

つまり、「まあまあ良い論文をたくさん書く」よりも、「本当に良い論文を一本書く」ほうが、キャリアへのインパクトは圧倒的に大きい、ということを表しています。

自分のキャリアと評判は、自分が出した一番良い研究・論文で決まる

目的「○○ で有名な XX さん」
AlexNet の Alex Krizhevsky (アレックス・クリジェフスキー)
ImageNet の Li FeiFei
GPT2・Whisper の Alec Radford (アレック・ラドフォード)
GAN の Ian Goodfellow
AlphaGo の David Silver

狭い分野で良いので、1番になる重要性

-------------------------------------------------------------------------------
どこで研究するか

前回、「ジョインするスタートアップの選び方」のエピソードで説明した

人・人・人
   尊敬できる指導教官・上司・同僚・ラボの仲間
実績
   研究所・研究者としての実績
   口だけ出す共同研究者・指導教官
   （過去に）筆頭著者としてどういう論文を出してきたか
   コードを書いた形跡？
GPU の量
データの量
興味のある応用分野、アプリケーション

Kiri Wagstaff (2012): Machine Learning That Matters
「役に立つ機械学習」「実際の世界にインパクトを与える機械学習」

評価指標への過剰なフォーカス
ベンチマークで SoTA を取ったか

UCI archive
Iris 
https://archive.ics.uci.edu/dataset/53/iris
花のがく片と花びらの長さから、アヤメ属（Iris）の3種類の花を分類する

実際の世界にどのぐらいインパクトを与えたか

Section 2
-------------------------------------------------------------------------------
研究トピックの選び方

1. 

既存のモデルに毛が生えただけの研究をしない
「小さな改良にすぎない研究（incremental work）」

自分が大学院生の時「SVM (support vector machine) を使った○○」
「CRF (conditional random fields)を使った○○」
「RNN (recurrent neural network) を使った○○」
「LSTM (Long Short-Term Memory)、biLSTM、seq2seq モデル を使った ○○」
「ディープ・ラーニング (深層学習)」
「transformer を使った」
「LLM を使った」

SOTA かどうかだけに注目する研究をしない

ベンチマーク・データセット
ワークショップ、コンペティション・Shared Task を主催

「無かったので日本語でやってみました」→国内でのインパクトを狙うならあり　日本・日本語話者として重要
日本を出た国際社会、アカデミアでは微妙　日本語をデータセット、ベンチマークの一つとして扱うならあり
多言語モデルを作る、英語・スペイン語、フランス語、イタリア語
日本語・中国語・韓国語が無い　トークン化のところで


2. 
難しい問題にチャレンジする
人と違うことをやる

Andej Karpathy の「A Survival Guide to a PhD」ブログ記事
博士課程の学生向け　どうやって研究トピックを見つけるか
広く研究に携わる人にオススメ

「問題の困難さは、その問題の重要さ・インパクトに比例して増えない」
10倍重要・インパクトの大きい問題は、10倍難しく感じるが、実際は2, 3 倍難しいだけ

3. 
良い研究・悪い研究に対するテイストを磨く（2値分類問題）
学会に出る、ベストペーパーを見る
査読をする 分野に詳しくなるモチベーション、悪い論文と良い論文の区別が付く


研究分野、所属先を変えることを恐れてはいけない
2018 年 BERT が出てきたとき「伝統的な NLP は死んだ」
品詞解析、曖昧性解消、構文解析、照応解析

2022 年、LLM がメジャーになって、「NLP 自体が死んだ」
含意関係認識 (textual entailment)
感情分析 (sentiment analysis)
機械翻訳 (特定の言語の解析)


Section 3
-------------------------------------------------------------------------------
どう研究を進めるか

人とやる
同僚・上司・研究仲間を興奮させられるか
AI のスケール則によって、チームの規模も増えている
エンジニア、アノテータ

同僚・指導教官・上司とのコミュニケーションも同様
進捗、問題、相談があったらすぐ相談する

アジャイル開発
iterative 
短い頻繁なサイクルを素早く回していく

先に論文、もしくはドラフト (簡易的なドキュメント) を書く
ストーリー、Research Question、必要な実験を明確にする

コードやデータセットの公開を前提に進める
人に見られる、という前提が、良いコードを書くモチベーションになる

データを見る！
モデルの入力・出力が正しいか
バッチを見る、トークン化したら逆トークン化する
損失関数のグラフだけを見ない

新しいアイデアがあったら、まず100分の1，10分の1のデータでやる
スケール則、モデルサイズ、データサイズ、計算量に比例してべき乗則的に性能が改善する
そもそもそういう土台で勝負しない

LLM の場合
ゼロショット（prompting）
数ショット (few-shot)
文脈を広げていく
サンプリング・推論スケーリング
RAG、エージェント
教師ありファインチューニング
事前学習


キャッチーなタイトル、モデル・手法・データセット・ベンチマーク名も重要
日本人の論文のタイトルは長い傾向がある
分かりやすい Figure 1 をきちんとデザインして1ページ目に置く


ほとんどの論文は、学会に参加したり、Proceeding を見たりして発見しない
論文だけでなく、宣伝・広報 (トーク、SNS、ブログ記事、YouTube) も重要な研究活動の一部

良い論文を同僚とシェアする

---

Bill Freeman: How to write a good research paper
https://deviparikh.com/citizenofcvpr/static/slides/freeman_how_to_write_papers.pdf

Wagstaff (2012) Machine Learning that Matters
https://arxiv.org/abs/1206.4656

Andrej Karpathy: A Survival Guide to a PhD
https://karpathy.github.io/2016/09/07/phd/

Simon Peyton Jones: PhD: How to write a great research paper
https://www.youtube.com/watch?v=1AYxMbYZQ1Y
